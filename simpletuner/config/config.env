
export MODEL_TYPE='lora'
export FLUX=true

export CONTROLNET=false

export USE_DORA=false

export RESUME_CHECKPOINT="latest"


export CHECKPOINTING_STEPS=100
export CHECKPOINTING_LIMIT=10

export LEARNING_RATE=2e-4
export MODEL_NAME="black-forest-labs/FLUX.1-dev"



export DEBUG_EXTRA_ARGS=""
export TRACKER_PROJECT_NAME="flux-lora-training"
export TRACKER_RUN_NAME="run"


export MAX_NUM_STEPS=10000
export NUM_EPOCHS=0


export DATALOADER_CONFIG="config/multidatabackend.json"
export OUTPUT_DIR="/workspace/SimpleTuner/output/models"


export PUSH_TO_HUB="false"
export PUSH_CHECKPOINTS="false"
export HUB_MODEL_NAME=$TRACKER_PROJECT_NAME


export RESOLUTION=1024
export RESOLUTION_TYPE="pixel"
export MINIMUM_RESOLUTION=$RESOLUTION





export VALIDATION_GUIDANCE=3.5
export VALIDATION_GUIDANCE_RESCALE=0.0

export VALIDATION_GUIDANCE_REAL=1.0

export VALIDATION_NO_CFG_UNTIL_TIMESTEP=0

export VALIDATION_STEPS=100
export VALIDATION_NUM_INFERENCE_STEPS=20
export VALIDATION_NEGATIVE_PROMPT=""
export VALIDATION_SEED=42
export VALIDATION_RESOLUTION=$RESOLUTION



export TRAIN_BATCH_SIZE=4
export GRADIENT_ACCUMULATION_STEPS=1


export LR_SCHEDULE="constant_with_warmup"
export LR_WARMUP_STEPS=50


export CAPTION_DROPOUT_PROBABILITY=0.0

export METADATA_UPDATE_INTERVAL=65


export MAX_WORKERS=32

export READ_BATCH_SIZE=25
export WRITE_BATCH_SIZE=64

export VAE_BATCH_SIZE=12

export IMAGE_PROCESSING_BATCH_SIZE=32

export AWS_MAX_POOL_CONNECTIONS=128

export TORCH_NUM_THREADS=8

export DELETE_ERRORED_IMAGES=0
export DELETE_SMALL_IMAGES=0


export TRAINING_SCHEDULER_TIMESTEP_SPACING="trailing"
export INFERENCE_SCHEDULER_TIMESTEP_SPACING="trailing"

export MIN_SNR_GAMMA=5

export USE_XFORMERS=true


export USE_GRADIENT_CHECKPOINTING=true


export ALLOW_TF32=true
export OPTIMIZER="adamw_bf16"

export USE_EMA=false
export EMA_DECAY=0.999


export TRAINER_EXTRA_ARGS="--user_prompt_library=config/user_prompt_library.json --flux_guidance_value=1.0 --flux_lora_target=all+ffs --lora_rank=128 --keep_vae_loaded --adam_weight_decay=0.1 --max_grad_norm=1.0 --lr_scheduler=constant_with_warmup --validation_torch_compile=false --lora_init_type=default"


export TRAINING_SEED=8462


export MIXED_PRECISION="bf16"              
export PURE_BF16=true

export TRAINING_NUM_PROCESSES=1
export TRAINING_NUM_MACHINES=1
export ACCELERATE_EXTRA_ARGS=""   

export TRAINING_DYNAMO_BACKEND='no' 
export TOKENIZERS_PARALLELISM=false


